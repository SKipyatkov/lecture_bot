import logging
import re
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from collections import Counter
import string

logger = logging.getLogger(__name__)

class TextProcessorPlugin(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–ª–∞–≥–∏–Ω–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    
    @abstractmethod
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        pass
    
    @property
    @abstractmethod
    def name(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è –ø–ª–∞–≥–∏–Ω–∞"""
        pass
    
    @property
    def description(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –ø–ª–∞–≥–∏–Ω–∞"""
        return "–ë–∞–∑–æ–≤—ã–π –ø–ª–∞–≥–∏–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"

class PunctuationPlugin(TextProcessorPlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏"""
    
    @property
    def name(self) -> str:
        return "punctuation_enhancer"
    
    @property
    def description(self) -> str:
        return "–£–ª—É—á—à–∞–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Ä–∞—Å—Å—Ç–∞–≤–ª—è–µ—Ç –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è"
    
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        if not text or len(text.strip()) < 3:
            return text
        
        # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        text = re.sub(r'\s+', ' ', text.strip())
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –≤ –∫–æ–Ω–µ—Ü –µ—Å–ª–∏ –Ω–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        if text and text[-1] not in '.!?‚Ä¶':
            text += '.'
        
        # –ó–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        sentences = re.split(r'([.!?]+)', text)
        result = []
        
        for i, part in enumerate(sentences):
            if i % 2 == 0:  # –¢–µ–∫—Å—Ç–æ–≤–∞—è —á–∞—Å—Ç—å
                if part.strip():
                    # –ü–µ—Ä–≤–∞—è –±—É–∫–≤–∞ - –∑–∞–≥–ª–∞–≤–Ω–∞—è
                    part = part.strip()
                    if part and part[0].isalpha():
                        part = part[0].upper() + part[1:]
                    result.append(part)
            else:  # –ó–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                result.append(part)
        
        text = ''.join(result)
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'([.!?])\1+', r'\1', text)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –ø–æ—Å–ª–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'([.!?])([–∞-—èa-z])', r'\1 \2', text, flags=re.IGNORECASE)
        
        return text

class SpellingCorrectionPlugin(TextProcessorPlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç—ã—Ö –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫"""
    
    def __init__(self):
        self.common_mistakes = {
            'ru': {
                '—â–∞—Å': '—Å–µ–π—á–∞—Å', '–∫—Å—Ç–∞': '–∫—Å—Ç–∞—Ç–∏', '–≤–æ–æ–±—â–µ–º': '–≤ –æ–±—â–µ–º',
                '–∑–¥—Ä–∞—Å—Ç–µ': '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '–ø–∞–∫–∞': '–ø–æ–∫–∞', '—Å–ø—Å–∏–±–æ': '—Å–ø–∞—Å–∏–±–æ',
                '–ø–æ–∂–∞–ª—É–π—Å—Ç–æ': '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '—Å–µ–¥–Ω—è': '—Å–µ–≥–æ–¥–Ω—è', '—â–∞': '—Å–µ–π—á–∞—Å',
                '—á—ë': '—á—Ç–æ', '–Ω–∏—á–æ': '–Ω–∏—á–µ–≥–æ', '—Å–∫–æ–∫–∞': '—Å–∫–æ–ª—å–∫–æ', '–∫–∞–¥–∞': '–∫–æ–≥–¥–∞',
                '—á—ë—Ç–æ': '—á—Ç–æ-—Ç–æ', '–∑–¥–µ—Å—è': '–∑–¥–µ—Å—å', '—Ç—É—Ç–∞': '—Ç—É—Ç', '–∫–∞–Ω–µ—à': '–∫–æ–Ω–µ—á–Ω–æ',
                '–≤–∞—â–µ': '–≤–æ–æ–±—â–µ', '–≥–æ': '–∏–¥–µ–º', '–ø–æ-–ª—é–±–æ–º—É': '–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ',
                '—Ä–µ—Å–ø–µ–∫—Ç': '—É–≤–∞–∂–µ–Ω–∏–µ', '–∫—Ä–æ—Å–∞–≤—á–µ–≥': '–∫—Ä–∞—Å–∞–≤—á–∏–∫'
            },
            'en': {
                'plz': 'please', 'thx': 'thanks', 'u': 'you', 'r': 'are',
                'btw': 'by the way', 'imo': 'in my opinion', 'gonna': 'going to',
                'wanna': 'want to', 'gotta': 'got to', 'kinda': 'kind of',
                'sorta': 'sort of', 'ain\'t': 'is not', 'ya': 'you',
                'dunno': 'don\'t know', 'lemme': 'let me'
            }
        }
    
    @property
    def name(self) -> str:
        return "spelling_corrector"
    
    @property
    def description(self) -> str:
        return "–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞—Å—Ç—ã–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∏ —Å–ª–µ–Ω–≥"
    
    def _detect_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
        ru_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
        en_chars = len(re.findall(r'[a-z]', text.lower()))
        return 'ru' if ru_chars > en_chars else 'en'
    
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        if not text:
            return text
        
        language = self._detect_language(text)
        mistakes = self.common_mistakes.get(language, {})
        
        for wrong, correct in mistakes.items():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤ —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–Ω—è—Ç—å —á–∞—Å—Ç–∏ —Å–ª–æ–≤
            text = re.sub(r'\b' + re.escape(wrong) + r'\b', correct, text, flags=re.IGNORECASE)
        
        return text

class KeywordExtractorPlugin(TextProcessorPlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
    
    @property
    def name(self) -> str:
        return "keyword_extractor"
    
    @property
    def description(self) -> str:
        return "–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –≤–∞–∂–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"
    
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        if not text:
            return text
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        original_text = text
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞)
            words = re.findall(r'\b\w{4,}\b', text.lower())
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
            word_freq = Counter(words)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
            keywords = [word for word, count in word_freq.most_common(10) if count > 1]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if context is not None:
                context['keywords'] = keywords
                context['word_frequency'] = dict(word_freq.most_common(20))
            
            logger.debug(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
        
        return original_text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

class TextSummaryPlugin(TextProcessorPlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"""
    
    @property
    def name(self) -> str:
        return "text_summarizer"
    
    @property
    def description(self) -> str:
        return "–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"
    
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        if not text or len(text) < 100:
            return text
        
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = re.split(r'[.!?]+', text)
            valid_sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
            
            if len(valid_sentences) <= 3:
                return text
            
            summary = '. '.join(valid_sentences[:3]) + '.'
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if context is not None:
                context['summary'] = summary
                context['original_length'] = len(text)
                context['summary_length'] = len(summary)
                context['compression_ratio'] = round(len(summary) / len(text) * 100, 1)
            
            logger.debug(f"üìù –°–æ–∑–¥–∞–Ω–æ –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {len(summary)}/{len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return summary
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return text

class EmotionDetectionPlugin(TextProcessorPlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        self.emotion_words = {
            'positive': {
                'ru': ['—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ', '–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ', 
                      '—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤', '—É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ', '—Å–ø–∞—Å–∏–±–æ', '–±–ª–∞–≥–æ–¥–∞—Ä—é'],
                'en': ['good', 'great', 'excellent', 'wonderful', 'amazing', 
                      'happy', 'pleased', 'thanks', 'thank you', 'awesome']
            },
            'negative': {
                'ru': ['–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ', '–≥—Ä—É—Å—Ç–Ω–æ', '–∑–ª–æ–π',
                      '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–ø—Ä–æ—Ç–∏–≤–Ω—ã–π', '—Å–∫—É—á–Ω–æ', '—É—Å—Ç–∞–ª'],
                'en': ['bad', 'terrible', 'awful', 'sad', 'angry',
                      'disappointed', 'hate', 'boring', 'tired', 'upset']
            }
        }
    
    @property
    def name(self) -> str:
        return "emotion_detector"
    
    @property
    def description(self) -> str:
        return "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É —Ç–µ–∫—Å—Ç–∞"
    
    def _detect_language(self, text: str) -> str:
        ru_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
        en_chars = len(re.findall(r'[a-z]', text.lower()))
        return 'ru' if ru_chars > en_chars else 'en'
    
    def process(self, text: str, context: Dict[str, Any] = None) -> str:
        if not text:
            return text
        
        language = self._detect_language(text)
        text_lower = text.lower()
        
        positive_count = 0
        negative_count = 0
        
        # –°—á–∏—Ç–∞–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        for word in self.emotion_words['positive'][language]:
            positive_count += len(re.findall(r'\b' + re.escape(word) + r'\b', text_lower))
        
        # –°—á–∏—Ç–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        for word in self.emotion_words['negative'][language]:
            negative_count += len(re.findall(r'\b' + re.escape(word) + r'\b', text_lower))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—â—É—é —ç–º–æ—Ü–∏—é
        emotion = 'neutral'
        if positive_count > negative_count:
            emotion = 'positive'
        elif negative_count > positive_count:
            emotion = 'negative'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if context is not None:
            context['emotion_analysis'] = {
                'emotion': emotion,
                'positive_words': positive_count,
                'negative_words': negative_count,
                'language': language
            }
        
        logger.debug(f"üòä –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π: {emotion} (+{positive_count}/-{negative_count})")
        
        return text

class PluginSystem:
    """–°–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–ª–∞–≥–∏–Ω–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        self.plugins: List[TextProcessorPlugin] = []
        self.enabled_plugins: List[str] = []
        self._load_builtin_plugins()
    
    def _load_builtin_plugins(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø–ª–∞–≥–∏–Ω—ã"""
        self.register_plugin(PunctuationPlugin())
        self.register_plugin(SpellingCorrectionPlugin())
        self.register_plugin(KeywordExtractorPlugin())
        self.register_plugin(TextSummaryPlugin())
        self.register_plugin(EmotionDetectionPlugin())
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–∞–µ–º –≤—Å–µ –ø–ª–∞–≥–∏–Ω—ã
        self.enabled_plugins = [plugin.name for plugin in self.plugins]
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.plugins)} –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –ø–ª–∞–≥–∏–Ω–æ–≤")
    
    def register_plugin(self, plugin: TextProcessorPlugin):
        """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π –ø–ª–∞–≥–∏–Ω"""
        if any(p.name == plugin.name for p in self.plugins):
            logger.warning(f"–ü–ª–∞–≥–∏–Ω {plugin.name} —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")
            return
        
        self.plugins.append(plugin)
        logger.info(f"‚úÖ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø–ª–∞–≥–∏–Ω: {plugin.name} - {plugin.description}")
    
    def enable_plugin(self, plugin_name: str):
        """–í–∫–ª—é—á–∞–µ—Ç –ø–ª–∞–≥–∏–Ω"""
        if plugin_name not in self.enabled_plugins:
            self.enabled_plugins.append(plugin_name)
            logger.info(f"‚úÖ –í–∫–ª—é—á–µ–Ω –ø–ª–∞–≥–∏–Ω: {plugin_name}")
    
    def disable_plugin(self, plugin_name: str):
        """–í—ã–∫–ª—é—á–∞–µ—Ç –ø–ª–∞–≥–∏–Ω"""
        if plugin_name in self.enabled_plugins:
            self.enabled_plugins.remove(plugin_name)
            logger.info(f"‚úÖ –í—ã–∫–ª—é—á–µ–Ω –ø–ª–∞–≥–∏–Ω: {plugin_name}")
    
    def process_text(self, text: str, enabled_plugins: List[str] = None) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –≤—Å–µ –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ –ø–ª–∞–≥–∏–Ω—ã
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not text:
            return {'text': text, 'metadata': {}}
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        plugins_to_use = enabled_plugins if enabled_plugins is not None else self.enabled_plugins
        
        context = {
            'original_text': text,
            'processed_plugins': [],
            'processing_stats': {}
        }
        
        result_text = text
        
        for plugin in self.plugins:
            if plugin.name in plugins_to_use:
                try:
                    start_time = logger.debug(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–ª–∞–≥–∏–Ω–æ–º: {plugin.name}")
                    result_text = plugin.process(result_text, context)
                    context['processed_plugins'].append(plugin.name)
                    logger.debug(f"‚úÖ –ü–ª–∞–≥–∏–Ω {plugin.name} –∑–∞–≤–µ—Ä—à–∏–ª –æ–±—Ä–∞–±–æ—Ç–∫—É")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–≥–∏–Ω–∞ {plugin.name}: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –¥—Ä—É–≥–∏–º–∏ –ø–ª–∞–≥–∏–Ω–∞–º–∏
        
        context['final_text'] = result_text
        context['total_plugins_used'] = len(context['processed_plugins'])
        
        return {
            'text': result_text,
            'metadata': context
        }
    
    def get_available_plugins(self) -> List[Dict[str, str]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–ª–∞–≥–∏–Ω–æ–≤"""
        return [
            {
                'name': plugin.name,
                'description': plugin.description,
                'enabled': plugin.name in self.enabled_plugins
            }
            for plugin in self.plugins
        ]
    
    def get_plugin_info(self, plugin_name: str) -> Optional[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø–ª–∞–≥–∏–Ω–µ"""
        for plugin in self.plugins:
            if plugin.name == plugin_name:
                return {
                    'name': plugin.name,
                    'description': plugin.description,
                    'enabled': plugin.name in self.enabled_plugins
                }
        return None

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–ª–∞–≥–∏–Ω–æ–≤
plugin_system = PluginSystem()